{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a10fd3",
   "metadata": {
    "papermill": {
     "duration": 0.002409,
     "end_time": "2026-01-01T15:47:26.710767",
     "exception": false,
     "start_time": "2026-01-01T15:47:26.708358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üé•AI-Powered Videos/ lecture Summarization\n",
    "> **Transform hours of video into minutes of reading.**\n",
    "\n",
    "### üìñ Overview\n",
    "**How it works:**\n",
    "1. installing transformer\n",
    "2. extract text from video\n",
    "3. summarization pipeline\n",
    "4. summrized text generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602b14e",
   "metadata": {
    "papermill": {
     "duration": 0.001582,
     "end_time": "2026-01-01T15:47:26.714216",
     "exception": false,
     "start_time": "2026-01-01T15:47:26.712634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installing Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51d96cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:47:26.718250Z",
     "iopub.status.busy": "2026-01-01T15:47:26.718017Z",
     "iopub.status.idle": "2026-01-01T15:47:40.130639Z",
     "shell.execute_reply": "2026-01-01T15:47:40.129909Z"
    },
    "papermill": {
     "duration": 13.416527,
     "end_time": "2026-01-01T15:47:40.132300",
     "exception": false,
     "start_time": "2026-01-01T15:47:26.715773",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.38.0\r\n",
      "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (3.20.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (2.0.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (2.32.5)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.0)\r\n",
      "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.0) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (1.2.1rc0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.0) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.0) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.0) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.0) (2025.11.12)\r\n",
      "Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.22.1\r\n",
      "    Uninstalling tokenizers-0.22.1:\r\n",
      "      Successfully uninstalled tokenizers-0.22.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.57.1\r\n",
      "    Uninstalling transformers-4.57.1:\r\n",
      "      Successfully uninstalled transformers-4.57.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.38.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.38.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506d772",
   "metadata": {
    "papermill": {
     "duration": 0.002408,
     "end_time": "2026-01-01T15:47:40.137464",
     "exception": false,
     "start_time": "2026-01-01T15:47:40.135056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract text from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c0cdc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:47:40.143488Z",
     "iopub.status.busy": "2026-01-01T15:47:40.142952Z",
     "iopub.status.idle": "2026-01-01T15:47:43.398243Z",
     "shell.execute_reply": "2026-01-01T15:47:43.397521Z"
    },
    "papermill": {
     "duration": 3.260269,
     "end_time": "2026-01-01T15:47:43.399993",
     "exception": false,
     "start_time": "2026-01-01T15:47:40.139724",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\r\n",
      "  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube_transcript_api) (0.7.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube_transcript_api) (2.32.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (2025.11.12)\r\n",
      "Downloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: youtube_transcript_api\r\n",
      "Successfully installed youtube_transcript_api-1.2.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f74e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:47:43.407139Z",
     "iopub.status.busy": "2026-01-01T15:47:43.406481Z",
     "iopub.status.idle": "2026-01-01T15:47:44.605485Z",
     "shell.execute_reply": "2026-01-01T15:47:44.604923Z"
    },
    "papermill": {
     "duration": 1.204292,
     "end_time": "2026-01-01T15:47:44.607138",
     "exception": false,
     "start_time": "2026-01-01T15:47:43.402846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the YouTube video ID from a URL.\n",
    "    Raises ValueError if no 'v' parameter is found.\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    qs = parse_qs(parsed.query)\n",
    "    video_ids = qs.get('v')\n",
    "\n",
    "    if not video_ids:\n",
    "        raise ValueError(f\"No video id found in URL: {url}\")\n",
    "    return video_ids[0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.youtube.com/watch?v=rVfZHWTwXSA\"\n",
    "\n",
    "    video_id = extract_video_id(url)\n",
    "\n",
    "    api = YouTubeTranscriptApi()\n",
    "    fetched = api.fetch(video_id, languages=['en'])\n",
    "\n",
    "    text = \"\\n\".join(snippet.text for snippet in fetched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56eceec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:47:44.613941Z",
     "iopub.status.busy": "2026-01-01T15:47:44.613354Z",
     "iopub.status.idle": "2026-01-01T15:47:44.619961Z",
     "shell.execute_reply": "2026-01-01T15:47:44.619296Z"
    },
    "papermill": {
     "duration": 0.011867,
     "end_time": "2026-01-01T15:47:44.621794",
     "exception": false,
     "start_time": "2026-01-01T15:47:44.609927",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All right. [NOISE] Um, let\\'s get started.\\nSo, um, let\\'s see, logistical reminder,\\nuh the class midterm, um,\\nis this Wednesday and it\\'s 48-hour take-home midterm.\\nUm, and the logistical details you can find,\\nuh, at this Piazza post, okay?\\nSo the midterm will start Wednesday evening.\\nYou have 48 hours to do it and then submit it online through Gradescope, uh,\\nand because of the midterm,\\nthere won\\'t be a section,\\nuh, this Friday, okay?\\nOh and the midterm will cover everything up to and including EM,\\nuh, which we\\'ll spend most of today talking about, okay?\\nCertainly don\\'t look so stressed. It\\'ll be fun.\\n[LAUGHTER].\\nMaybe. All right.\\nUm, so what I\\'d like to do today is start our foray into, uh, unsupervised learning.\\nUh, so far I\\'ve spent a lot of time on\\nsupervised learning algorithms including advice on\\nhow to apply supervised learning algorithms.\\nThese pens are great.\\nIn which you\\'d have, you know,\\npositive examples and negative examples and you run\\nlogistic regression or something or SVM or\\nsomething to find the line- find the decision boundary between them.\\nUm, in unsupervised learning,\\nyou\\'re given unlabeled data.\\nSo rather than given data with x and y,\\nyou\\'re given only x.\\nAnd so your training set now looks like X1,\\nX2, up to Xm.\\nAnd you\\'re asked to find something interesting about the data.\\nUh, so the first unsupervised learning algorithm we\\'ll talk about\\nis clustering in which given a dataset like this,\\nhopefully, we can have an algorithm that can figure\\nout that this dataset has two separate clusters.\\nUm, and so one of the most common uses of clustering is, uh, market segmentation.\\nIf you have a website,\\nyou know, selling things online,\\nyou have a huge database of many different users and run clustering\\nto decide what are the different market segments, right?\\nSo there may be, you know,\\npeople of a certain age range, of a certain gender,\\npeople of a different age range,\\ndifferent level of education,\\npeople that live in the East Coast versus West Coast versus other parts of the country.\\nBut by clustering you can group people into,\\nuh, different groups, right?\\nSo, um, I want to show you an animation of, um,\\nreally the most commonly used er,\\ner, clustering algorithm called k-means clustering.\\nAnd let me show you an animation of what k-means does and\\nthen we\\'ll write- write out the math an- an- and tell you how you can implement it.\\nSo, um, let\\'s say you\\'re given data like this.\\nSo all these are unlabeled examples.\\nUh, so just x plotted here.\\nAnd we want an algorithm to try to find maybe the two clusters here.\\nUh, the first step of k-means is to pick two points\\ndenoted by the two crop- two crosses called cluster centroids and,\\nuh, the cluster centroids are your best guess for\\nwhere the centers of the two clusters you\\'re trying to find.\\nAnd then k-means is an iterative algorithm and repeatedly you do two things.\\nSo first thing is, go through each of your training examples.\\nOh I\\'m sorry. Oh okay. Thank you.\\nAll right. Let me know if that happens again.\\nOkay. Right. So, uh, you guys saw that, right?\\nSo. Right near two cluster centroids.\\nSo the first thing you do is go through each of your training examples,\\nthe green dots and for each of them you color them either red\\nor blue depending on which is the closer cluster centroid.\\nSo here we\\'ve taken every dot and colored it in red or blue\\ndepending on which side it is- which cluster centroid it\\'s closer to.\\nAnd then, uh, the second thing you do, uh, is,\\nuh, look at all the blue dots and compute the average, right?\\nJust find the mean of all the blue dots,\\num, and move the blue cluster centroid there.\\nAnd similarly, look at all the red dots- and look at only the red dots\\nand find a mean- finding the- oh now what\\'s wrong with this?\\nLet\\'s say- oh this thing though is very strange.\\nRight. Apparently, if I keep moving my mouse,\\nit doesn\\'t do that. All right. Thank you.\\nUh, and then find the mean of all the red dots and move your,\\nuh, red cluster centroid there.\\nSo let me do that, right?\\nSo the cluster centroids move as follows, um,\\nto the mean of the red and the blue dots and this is\\njust a standard arithmetic average, right?\\nUh, and then you repeat again where you, er,\\nlook at each of the dots and color it either red or\\nblue depending on which cluster centroid is closer.\\nSo when I recolor every point based on,\\nyou know, what\\'s closer,\\nso that\\'s the new set of colors, right?\\nUm, and then the second part of the algorithm was\\nagain look at the blue dots, find the mean,\\nlook at the red dots, find the mean,\\nand then move the cluster centroids over.\\n[NOISE] Excuse me, uh,\\nto that mean, okay?\\nUm, and so, er,\\nand it turns out if you keep running the algorithm, nothing changes.\\nSo the algorithm has converged.\\nSo if you look at this picture and you repeatedly color each point\\nred or blue depending on which cluster centroid is closer, nothing changes.\\nAnd you repeatedly look at each of the two clusters of color dots\\nand compute a mean and move the clu- clu- clusters there, nothing changes.\\nSo this algorithm has converged even if you keep on running these two steps, okay?\\nSo um, let\\'s see.\\nLet\\'s write down in math what we just did.\\n[NOISE] All right. So this is,\\num, a clustering algorithm and specifically this is a k-means clustering algorithm.\\nSo your dataset now does not come with any labels.\\nUm, and so in, uh,\\nk-means, step one is, uh,\\ninitialize the cluster centroids, right?\\nI\\'m gonna call them Mu_1 up to Mu_k, uh, randomly, okay?\\nSo this was a step where you plop down the red cross and the blue cross.\\nUh, and when they did it on the PowerPoints, you know,\\nI did it as if we\\'re just choosing these as random vectors.\\nIn practice a good way of the- actually the most common way\\nto select a random initial cluster centroid isn\\'t quite what I showed,\\nis to actually pick k examples out of your training set and just\\nset the cluster centroids to be equal to k randomly chosen the examples, right?\\nSo in a low-dimensional space like a 2D plot,\\nyou know, you can do on the diagram,\\nit doesn\\'t really matter but when you work with very high dimensional datasets,\\nthe more common way to initialize these is just pick, you know,\\nk training examples and set the cluster centroids to be\\nat exactly the location of those examples.\\nBut then low dimensionless spaces it- it- you know,\\nit doesn\\'t make a big difference.\\nUm, and then next you repeat until convergence.\\nUm, step one is-\\nright? So this is a- well\\nnow I\\'ll just write this down,\\nokay? Um, so does that make sense?\\nSo the two steps you would alternate between the first one\\nis set Ci for every value of i.\\nSo for every example,\\nset Ci equal to, you know,\\neither 1 or 2 depending on whether, er,\\nthat example Xi is closer to cluster centroid one or cluster centroid two, right?\\nSo ju- just take each point and color either red or blue.\\nUh, or and represent that by setting Ci equals 1 or 2,\\ner, if you have two clusters.\\nIf k is equal to 2, right? Oh yeah.\\n[inaudible]\\nOh. Er, the notes say L1 norm squared?\\nFrom this morning?\\nUh, what notes were sent out this morning?\\n[inaudible].\\nOh that\\'s red. It shouldn\\'t be L1 norm.\\nUh, if it says L1 norm,\\nthat\\'s a mistake. Sorry about that.\\nEr, but usually- an- and it turns out whether you use\\nL2 norm and L2 norm squared that gives you\\nthe same answer because the algorithm is the same either way.\\nBut it is usually- do we have a typo on the notes?\\n[inaudible].\\nOh I see. Oh got it. Oh- oh- oh okay.\\nLet\\'s say in notes we wrote that.\\nOkay. Cool. But by default,\\nwhen we write that norm we actually use- we mean L2 norm.\\nYeah, right? But by- by default this is the L2 norm of x if is unspecified.\\nEr, if it\\'s L1 norm, we usually write this.\\nSo L2 norm is more common and with or without the square it you get the same result.\\nOkay. Cool. Thank you. All right.\\nSo let\\'s color the dots.\\nUm, paint each dot either red or blue.\\nUh, and then, um, uh,\\nfor this, um, this is,\\nyou know, some key examples and take\\nall the examples assigned to a certain cluster, right?\\nAssigned to cluster j and set Mu_j to\\nbe average of all the points assigned to that cluster J. Yeah.\\n[inaudible]\\nOh sure. Er, no that does not work.\\nUh, you know, I don\\'t think -I don\\'t know if I have- all right.\\nNow, that the black markers are working,\\num, this is better?\\nAll right let me try to use this?\\nIs there a part of this that\\'s unclear?\\nIf this part you can\\'t see, I\\'ll write it out more clearly.\\nYes. Go ahead. Let\\'s go ahead.\\n[inaudible].\\nOh sure. How I do it, lights in front?\\n[inaudible].\\nGot it. Let there be light.\\nAll right. Awesome great.\\nThat was an easy request to satisfy, great, you know, okay.\\nI guess we\\'ll actually look at it for another minute.\\nAll right. Is that okay? Thank you.\\nOkay. This wasn\\'t part of it.\\nOkay. All right. Now, I can move it up.\\n[NOISE].\\nAll right. Um, so it turns out that,\\nuh, um, this algorithm can be proven to converge.\\nUm, the, exactly why it is written out in the lecture notes.\\nBut it turns out, if you write this as\\na cost function, right?\\nUm, so the cost function for a certain set of assignments of, uh,\\npoints of examples to cluster\\ncentroids and for a certain set of positions of the cluster centroids.\\nSo, so c, these are the assignments and these are the centroids, right?\\nSo, so this cost here is sum of your training\\nset of what\\'s the square distance between each point,\\nand the cluster centroid it is assigned to, right?\\nSo it turns out, um,\\nI want to prove this, uh,\\nlittle bit more detail in lecture notes but I\\'m going to prove this.\\nIt turns out that on every iteration,\\nk-means would drive this cost function down,\\num, and so, you know,\\nbeyond a certain point this cost function,\\nit can\\'t go even,\\nit can\\'t go, uh, uh, any lower.\\nWell, this, this can\\'t go below 0, right?\\nAnd so this shows that k-means must converge,\\nor at least this function must converge because it\\'s, uh, a\\nstrictly non-negative function that\\'s going down on every iteration.\\nSo at some point, it has to stop going down,\\nand then you could declare k-means are converged.\\nUm, in practice, if you run k-means in a very,\\nvery large data set,\\nthen as you plot the number of iterations, uh,\\nj may go down,\\nand you know, and,\\nand just because of,\\na lack of compute or lack of patience,\\nyou might just stop this running after a while.\\nIt is going down too slowly.\\nSo that\\'s sort of k-means in practice where maybe\\nit hasn\\'t totally converged, we just cut it off and call it good enough.\\nUm, now, uh, uh,\\nthe most frequently asked question I get for k-means is how do you choose k?\\nIt turns out that, um,\\nwhen I use k-means,\\nI still usually choose k by hand.\\nAnd so, and, and this is why.\\nWhich is in unsupervised learning,\\num, sometimes it\\'s just ambiguous, right?\\nHow many clusters there are [NOISE].\\nRight? Um, with this dataset,\\nsome of you will see two clusters,\\nand some of you will see four clusters,\\nand it\\'s just inherently ambiguous what is the right number of clusters.\\nSo there are some formulas you can find online,\\nthe criteria like AIC and BIC for automatically choosing the number of clusters.\\nIn practice, I tend not to use them because, uh, um,\\nI usually look at the downstream application of what you actually want\\nto use k-means for in order to make a decision on the number of clusters.\\nSo for example, if you\\'re doing a market segmentation,\\num, you know, because your marketers want to design different marketing campaigns, right?\\nFor different groups of users,\\nthen your marketers might have the bandwidth to design four separate marketing campaigns,\\nbut not 100 marketing campaigns.\\nSo that would be a good reason to choose four clusters rather than 100 clusters.\\nSo it\\'s often, uh, uh,\\nif you look at the purpose of what you\\'re doing this for.\\nUm, I think in the previous exercise,\\nuh, in the homework, you see a, um,\\nimage compression, uh, exercise where you want to cluster,\\nuh, colors into smaller number of clusters.\\nYou implement this. This is actually one of the most fun exercises I think.\\nUm, uh, uh, that, uh,\\nuh, but so there you\\'d, you know, be saying, well,\\nhow much do you want to compress the image to decide how many clusters to,\\nto try to use, okay?\\nSo I usually, um, pick the number of clusters, you know,\\neither manually or looking at what you want to use k-means cluster for.\\nUm, when we\\'re trying to cluster news articles, uh,\\nthe Google News example,\\nI think I showed in the first lecture.\\nYou say, well, how many clusters is going to make sense for,\\nfor, for news articles, okay?\\nAll right. So good. So, uh, yeah?\\n[inaudible].\\nOh sure. Well, k-means get stuck on local minima.\\nYes, k-means gets stuck on sort of local minima sometimes.\\nAnd so, if you\\'re worried about local minima,\\nthe thing you can do is, uh,\\nrun k-means, say, 10 times, or 100 times,\\nor 1000 times from different random initializations of the cluster centroids.\\nAnd then run it, you know, say 100 times, uh,\\nand then pick whichever run results in the lowest value for this cost function, okay?\\nAll right. Um, so you\\'ll play with this more in, um,\\nuh, in the programming exercise.\\nNow, um, there\\'s a,\\nthere\\'s a problem that seems closely related.\\nUm, but, but it\\'s actually\\nquite different ways to write the algorithms which is density estimation.\\nSo, so let me motivate this.\\nUm, I actually have a- well, right,\\nsometime back had some friends working on a problem which I\\'ll simplify a little bit,\\num, of, uh, uh, you know,\\nyou have aircraft engines coming off the assembly line.\\nAll right. And every time an aircraft engine comes off the assembly line,\\nyou measure some features of these engines.\\nYou measure some features about the vibration,\\nand you measure some features about the heat that the aircraft engine is producing.\\nAnd, um, let\\'s say that you get a dataset,\\nright, that looks like this, okay?\\nAnd, um, the anomaly detection problem\\nis if you get a new aircraft engine that comes off the assembly line,\\nand if the vibration feature takes on this value,\\nand the heat feature takes on this value,\\nis that aircraft engine an anomalous one,\\nis it an unusual one, right?\\nAnd so the application of this is,\\num, that as your aircraft engine comes off the assembly line,\\nif you see a very unusual signature in terms of\\nthe vibrations and the heat the aircraft engine is generating,\\nthen probably something is wrong with this aircraft engine,\\nand you have your people, have your,\\nhave your team inspect it further or test it further,\\nuh, before you ship the airplane,\\nbefore you ship the engine to a,\\nto a airplane maker and then something goes wrong in the air, and there\\'s a,\\nthere\\'s a major accident,\\nor major disaster, right?\\nAnd so anomaly detection, uh, uh,\\nis most commonly done,\\nor one of the common ways to, um,\\nimplement anomaly detection is the model p of\\nx which is given all of these blue examples,\\ngiven all of these dots,\\ncan you model what is the density from which x was drawn?\\nSo then if p of x is very small,\\nthen you flag an anomaly, right?\\nMeaning that, Gee, I think something\\'s funny here, uh,\\nand maybe someone should inspect this aircraft engine a little bit further.\\nUm, so anomaly detection is used for,\\na task like this,\\nfor an inspection task like this.\\nUm, it\\'s used for,\\num, uh, many years ago,\\nI was actually working with some telecoms providers, you know, uh, uh,\\nhelping out telecoms company on, um,\\nanomaly detection to figure out if something\\'s\\ngone wrong with a cell tower network, right?\\nSo if one day one of the cell towers start throwing off\\nnetwork patterns that seem very unusual,\\nthen maybe something\\'s wrong with that cell tower,\\nlike something\\'s gone wrong.\\nWe sent out the technicians to fix it.\\nUh, it is also used for computer security.\\nIf a computer, say if a computer at Stanford starts sending out very strange,\\nyou know, um, uh, uh, network traffic,\\nthat\\'s very unusual relative to everything it\\'s done before,\\nrelative what this is,\\nis a very anomalous network traffic,\\nthen maybe IT staff should have a look to\\nsee if that particular computer has been hacked.\\nSo these are some of the applications of anomaly detection.\\nAnd the good way to do this is,\\ngiven an unlabeled data set, model p of x.\\nAnd then if you have very low probability samples,\\nyou flag that as a possible anomaly for further study.\\nNow, given this dataset,\\num, uh, how do you model this?\\nOne interesting thing about this green dot is that\\nneither the vibration nor the heat signature is actually out of range, right?\\nYou know, like there are a lot of aircraft engines with vibrations in that range.\\nThere are a lot of aircraft engines with heat in that range.\\nSo neither feature by itself is actually that unusual.\\nIt\\'s actually the combination of the two that is unusual.\\nUm, and so thus,\\nthus, what I want to do is,\\nuh, come up with an algorithm to model this.\\nAnd in fact, we\\'ll come up with an algorithm that can model, you know,\\nmaybe, maybe your data density looks like this,\\nmaybe more of an L shape like that.\\nBut how do you model p of x with the data coming from an L shape?\\nUm, and it turns out that there is no textbook distribution, right?\\nYou know, there isn\\'t, you know, if you look at a simple exponential family of model,\\nthe types of distributions,\\nthere is no distribution for modeling very,\\nvery complex distributions like this.\\nSo what we\\'re going to talk about is, um,\\nthe mixture of Gaussians model which we look at data like this,\\nand say, it looks like this data actually comes from two Gaussian.\\nThere\\'s one Gaussian, maybe there\\'s\\none type of aircraft engine that, that, that, you know,\\nis drawn from a Gaussian like the one below,\\nand a separate aircraft- type of\\naircraft engine that\\'s drawn from a Gaussian like that above.\\nAnd this is why there\\'s a lot of probability [NOISE] mass in the L-shaped region,\\nbut very low probability outside that L-shaped region, right?\\nAnd, and, and these ellipses I\\'m drawing are the contours of these two Gaussians, right?\\nAnd so, um, what I\\'d like to do next is,\\nuh, develop the mixture of Gaussians model, um,\\nwhich is useful for anomaly detection,\\nand, and, uh, uh, and,\\nand then this will lead us to our second unsupervised programming algorithm, okay?\\nSo, um, in order to make the mixture of Gaussians model a bit easier to develop,\\nlet me just use a one-dimensional example where x is in R, okay?\\nSo, um, let\\'s see.\\nSo let\\'s say that, uh,\\nwe gather a data set that looks like this.\\n[NOISE]\\nRight. So it\\'s just one row number.\\nSo it\\'s just on num- number line I plotted a few dots.\\nUm, so it looks like this data maybe comes from two Gaussians.\\nRight? It looks like, you know, there\\'s some data from this Gaussian.\\nAnd there\\'s some data from that Gaussian on the right.\\nUm, and is- and if only we knew.\\nRight? Which example had come from which Gaussian, if,\\nif we knew that these examples had come from Gaussian 1,\\nwhich I want to denote with crosses.\\nAnd if only we knew- no, that was here.\\nWhat- but actually this is fine. I\\'ll leave that one there.\\nIf only we knew that\\nthese examples had come from Gaussian 2 which I\\'m going to draw with Os,\\nthen we just fit Gaussian 1 to the crosses,\\nfit Gaussian 2 to the Os and then we\\'d be pretty much done.\\nRight? Um, oh, and, and, and sorry.\\nAnd so these are the two Gaussians.\\nAnd so the overall density would be something like this.\\nRight? Tha- that\\'s the probability.\\nA lot of probability mass on left.\\nA lot of probability mass on the right, low, less probability mass on the,\\nuh, in sort of in, in the middle.\\nOkay? So the overall density I\\'ll just draw again, would be,\\nlow high, low high something like that.\\nRight? Um, but the reason- and,\\nand, and if you actually had these labels.\\nIf you knew that these examples came from Gaussian 1,\\nthose examples come from Gaussian 2,\\nthen you can actually use an algorithm very similar to GDA,\\nGaussian discriminant analysis to fit this model.\\nUh, that the problem with this density estimation problem is,\\nyou just see this data and maybe the data came from two different Gaussians.\\nBut you don\\'t know which example actually came from which Gaussian.\\nOkay? So the EM algorithm or the expectation-maximization algorithm will allow us to, uh,\\nfit a model despite not knowing which Gaussian each example that come from.\\nSo let me first write down the,\\num, mixture of Gaussians model.\\nUh, and then we\\'ll describe the EM algorithm for this.\\nSo let\\'s imagine- let\\'s suppose that as a,\\num, so the term we sometimes use is latent,\\nbut latent just means hidden or unobserved.\\nUm, random variables z.\\nRight?\\nAnd x_i, z_i,\\num.\\nOkay? So- this part here.\\nSo let\\'s imagine that, um,\\nthere\\'s some hidden random variable z and,\\nand the term latent just means hidden or unobserved.\\nRight? It means that it exists but you don\\'t get to see the value directly.\\nSo when I say latent,\\nit just means hidden or unobserved.\\nSo let\\'s imagine that there\\'s a hidden or latent random variable z and,\\nuh, x_i and z_i have this joint distribution.\\nAnd this, this, this is very,\\nvery similar to the model you saw in Gaussian discriminant analysis.\\nBut z_i is multinomial with some set of parameters Phi.\\nFor a mixture of two Gaussians,\\nthis would just be Bernoulli with two values.\\nBut if it were a mixture of k Gaussians then z, you know,\\ncan take on values from 1 through k. [NOISE] Right?\\nUm, and it was two Gaussians it\\'ll just be Bernoulli.\\nAnd then once you know that one example comes from, uh.\\nGaussian number j, then x condition that z_i is equal to j.\\nThat is drawn from a Gaussian distribution with some mean and some covariance Sigma.\\nOkay? So the two unimportant ways.\\nThis is different than GDA.\\nUm, one, well, I\\'ve set z to be 1 of k values instead of one of two values.\\nAnd GDA, Gaussian discriminant analysis.\\nWe had z, you know, uh,\\nwhy the labels y took on one of two values.\\nUh, and then second is,\\nI have Sigma j instead of Sigma.\\nSo by, by convention when we fit mixture of Gaussians models,\\nwe let each Gaussian have his own covariance matrix Sigma.\\nBut you can actually force it to be the same way you want.\\nSo- but these are the trivial differences.\\nUh, the most significant difference is that,\\nin Gaussian discriminant analysis,\\nwe had labeled examples x_i, y_i.\\nWhere z- y was observed.\\nRight? And then the main difference between this and Gaussian discriminant analysis is,\\nnow we have replaced that with\\nthis latent or hidden random variable z_i that you do not get to see in the training set.\\nOkay?\\nSo now, uh,\\nactually you guys are right.\\nThese pens are terrible.\\nAll right. Oh, that was better.\\nCool. All right.\\nSo if we need the z_i\\'s.\\nRight? Then we can use,\\num, maximum likelihood estimation.\\nAll right? So if only we knew the value of the z_i\\'s, which we don\\'t.\\nBut if only we did, then we could use\\nmaximum likelihood estimation or MLE to estimate everything.\\nYou know. So we would write\\nthe log likelihood of the parameters.\\nRight? Equals sum, um,\\nlog p of x_i,\\nz_i, you know, given the parameters.\\nRight? And then you take the derivative,\\nset the derivatives equal to 0 and then you guys did this in problem set 1.\\nRight? And, and then you would find that Phi j is equal to\\n1 over m. Right?\\nOkay. So if only you knew the values of the z_i\\'s, uh,\\nthen you could use maximum likelihood estimates,\\num, will- and, and this is what you get.\\nAnd this is pretty much the formulas.\\nActually the- the- these two are exactly the formulas,\\nuh, we had for, uh, Gaussian discriminant analysis.\\nExcept with replace y with z.\\nRight? And then there\\'s some other formula for Sigma that\\'s written in the lecture notes.\\nBut I won\\'t, but I won\\'t write down here.\\nOkay? Um, but the reason we can\\'t use this,\\nuse these formulas is we don\\'t actually know what are the values of z.\\nSo what we will do in\\nthe EM algorithm\\nis two steps.\\nUm, in the first step,\\nwe will, uh, guess the value of the z\\'s.\\nAnd in the second step we will use\\nthese equations using the values of this z\\'s we just guessed.\\nSo let me- so, so sometimes in, um,\\nthe machine learning is something that\\'s called- there\\'s a bootstrap procedure\\nwhere you get something that runs an algorithm.\\nYou\\'re using your guesses and then you\\nupdate your guesses and then run the algorithm again.\\nLet me, let me make that concrete by writing this down.\\nSo the EM algorithm has two steps.\\nThe E-step, um,\\nalso called the expectation step is set to w i j.\\nSo w i j, um,\\nis going to be the probability that z_i is equal to j.\\nOkay? Um, given all the parameters.\\nAnd, and much as we did with, um,\\ngenerative learning algorithms, right,\\nwith generative learning algorithms,\\nwe used Bayes\\' rule to estimate the probability of y given x,\\nand so to compute this,\\nyou use a similar Bayes\\' rule type of calculation.\\nAnd so this would be [NOISE].\\nOops, right, um, where,\\nfor example this term here P of x_i given z_i equals j.\\nThis would be a Gaussian density, right?\\nThis comes from a Gaussian density with mean Mu j and covariance Sigma j, right?\\nAnd so this term here would be 1 over 2 Pi,\\nto the N over 2 Sigma j,\\nso one-half e to the negative one-half.\\nAll right. And then this term here,\\nI guess this would be Phi j,\\nthat\\'s just a Bernoulli probability,\\nremember z is multinomial.\\nRight, so z is multinomial with parameters Phi.\\nSo I guess the parameters Phi for multinomial distributions\\ntell you, what\\'s the chance of z being 1, 2, 3, 4,\\nand so on up to k, and so the chance of z_i being equal to k is\\njust- chance of z_i being equal to j is just Phi j right?\\nIt\\'s just v to the off one of the parameters in your multinomial probability for,\\num, for the odds of z being different values.\\nokay? And so, um,\\nand similarly the terms in the denominator.\\nThis term here is from Gaussian and that second term is from the,\\num, multinomial probability that you have for z.\\nAnd so that\\'s how you plug in all of these numbers and use Bayes rule and use\\nthis equation to compute given- all given the position of all these Gaussians,\\nwhat is the chance of w i j taking on a certain value, okay.\\nAnd, and so to make this really concrete,\\nyou remember how I guess 1 or 0s, or the other way, um,\\nIf you were to look at these,\\nuh, if you were to scan from right to left,\\nremember how, you know,\\nyou get a sigmoid function,\\nor the sigmoid can be this way or this way or it depends on the sign.\\nI guess if these are positive samples these are negatives.\\nYou have a sigmoid function like this.\\nAnd so w i j is just the height of this Sigma,\\nit\\'s just a chance of, you know,\\neach of these examples being,\\ncoming from either the z equals 1 or z equals 0\\nand then you store all of these numbers in the variables w i j.\\nOkay. So w i j is just to compute the posterior choice of this,\\nthis example coming from the left Gaussian versus the right Gaussian.\\nYou just saw that in the variable w i j.\\nSo that\\'s the E-step,\\num, and you compute the w i j for every single training example i.\\nRight? I think it\\'s the M-step is, um, yeah.\\n[BACKGROUND]\\nSorry, is this what?\\n[BACKGROUND]\\nOh this one.\\nYes.\\nSorry, yes. Thank you, there we go, thank you.\\nYes, there\\'s a following Gaussian.\\nOkay. So in the- so the E-step tells us, you know,\\nwe\\'re trying to guess the values of the z\\'s right,\\nwhen we figure out what\\'s the probability of z\\nbeing 1, 2, 3, 4 up to k was stored here.\\nAnd then in the M-step,\\nwhat we\\'re going to do is use the formulas we have for maximum likelihood estimation,\\nand I want you to compare these with the equations I had above, right.\\nOkay. Well, I hope you see.\\nSo these equations are a lot like the equations above,\\nexcept that instead of indicator z_i equals j,\\nwe replaced it with w i j, right?\\nWhich by the way is the expected value of this indicator function.\\nRight, because the expected value of an indicator function is\\njust equal to the probability of that thing in the middle being true.\\nOkay? Um, and then,\\nand then there\\'s a formula for Sigma j as well that you can get from the lecture notes,\\nbut i won\\'t, I won\\'t write down here.\\nOkay. So, um, one intuition of,\\num, this mixture of Gaussians algorithm is\\nthat it\\'s a little bit like k-means but with soft assignment.\\nSo in k-means, in\\nthe first step we would take each point and just assign it to one of the k,\\nk cluster centroids, right?\\nAnd if it was a little bit closer to\\nthe red cluster centroid than the blue cluster centroid,\\nwe would just assign it to the red cluster centroid.\\nSo even if it was just a little bit closer to one cluster centroid than another,\\nk means we just make what\\'s called a hard assignment meaning, you know,\\nwhatever cluster centroid it\\'s closest to,\\nwe just assigned it 100 percent of that ce- cluster centroid.\\nSo yeah, EM is,\\nuh, you can think, uh,\\nEM implements a softer way of assigning points to\\nthe different cluster centroids because instead of just\\npicking the one closest Gaussian center and assigning it there,\\nit uses these probabilities and gives it a waiting,\\nin terms of how much is assigned to Gaussian 1 versus Gaussian 2.\\nUm, and the second updates,\\nyou know, the means accordingly, right?\\nSum over all the x_i\\'s to the extent they\\'re assigned to\\nthat cluster centroid divided by\\nthe number of examples assigned to that cluster centroid.\\nOkay? So, so, so that\\'s one intuition be- between EM and k-means,\\num, and in a second, uh, uh, but,\\nbut when you run this algorithm,\\nit turns out that this algorithm will converge with some caveats I\\'ll get to later,\\nand this will find a pretty decent estimate, um,\\nof the parameters, you know,\\nof say fitting a mixture of two Gaussians model.\\nOkay? So this is, um,\\nthe- a- and so if you are given a dataset of say airplane engines,\\nyou can run this algorithm for the mixture of two Gaussians.\\nAnd then when a new airplane engine rolls off the assembly line, um, um, so,\\nso after you\\'re fitting the k-means algorithm,\\nyou now have a- after fitting the EM algorithm,\\nyou now have a joint density of a P of x comma z.\\nAnd so the density for x is just sum of all the values of z of P of x comma z.\\nAnd so, and so\\na mixture of Gaussians can fit distributions that look like this,\\nit can fit distributions that look like this, right?\\nThese are, these are both mixtures of two Gaussians.\\nSo this gives you a very rich family of models to fit very complicated distributions.\\nAnd now that, um, right,\\nand you can also fit, I don\\'t know, something like this.\\nSo this is a mixture of two Gaussians,\\nI guess one thin narrow Gaussian here and one much wider fatter Gaussian.\\nSo a mixture of two Gaussians can actually fit a model of different things, um, uh,\\ncan fit a lot- and a mixture of more than two Gaussians can fit even richer models.\\nAnd so by doing this,\\nyou can now model P of x for many complicated densities,\\nor including this one, right,\\nthis example I had just now.\\nThis will allow you to fit\\na probability density function that puts a lot of probability models on,\\non a region that looks like this.\\nAnd so when you have a new example you can evaluate P of x,\\nand if P of x is large,\\nthen you can say nope this looks okay and the P of x is less than Epsilon.\\nYou can flag an anomaly and say take a look- take another look at this here.\\nOkay? So, um, I kind just wrote down this algorithm,\\nwith a little bit of a hand-wavy explanation for how it\\'s derived, right?\\nSo like I said, if only you knew the values of C and just use maximum likelihood estimation,\\nso let\\'s guess the values of z and plug that\\ninto the formulas of maximum likely estimation.\\nIt turns out that hand-wavy explanation works,\\nin the particular case of, um,\\nthe EM mixtures of Gaussians but that there is a more formal way of\\nderiving the EM algorithm that shows that this is a maximum likelihood estimation algorithm,\\nand that they converge at at least a local optimum.\\nUm, and in particular,\\nthere- what we\\'ll do is show that if your goal is, um,\\nuh given a model P of x,\\nz parameterized by Theta,\\nif your goal is to maximize P of x,\\nright? Oh, excuse me.\\nSo this is what maximum likelihood is supposed to do.\\nThat EM is exactly trying to do that, okay.\\nSo, um, I\\'ll go on in a minute to present this more general derivation,\\nthe - the form of general derivation of the EM algorithm tha- that doesn\\'t rely on\\nthis hand-wavy argument of\\nI guess it\\'s easier use maximum likelihood with the guess values.\\nSo I\\'ll do the the rigorous derivation of EM in a minute.\\nBut before I do that, let me just pause and check if there any questions.\\nYeah.\\n[inaudible].\\nUm, yeah,\\nuh, maybe- let\\'s see.\\nMaybe I\\'ll help to not think of them as weights.\\nUm, yeah, I think thi- this is actually the weighting you assigned to a certain Gaussian,\\nso there\\'s one intuition, uh,\\nhen - hence the weights, but, um,\\num, let me think,\\nwhat\\'s going to explain this?\\nSo one way to think of this as wij is\\nhow much xi is assigned to,\\nyou know, to- to- to the um, ¬µj Gaussian.\\nSo, um, wij is the strength of how\\nstrongly you want to assign that training example\\nxi to that cluster or to that- to that particular Gaussian.\\nUm, and so this is the number of 2,\\n0, and 1 right?\\nAnd, uh, the strength of all the assignments,\\nand every point is a sign with a total strength equal to 1,\\nbecause all these properties must sum up to 1.\\nAnd so, when I take this point and assign it, you know,\\n0.8 to a more close Gaussian and 0.2 to a more distant Gaussian.\\nAnd this is our guess for, you know,\\nwell there\\'s an 80% chance that it came with that Gaussian and a 20% chance\\nit came with the second Gaussian. That makes sense?\\n[inaudible].\\nOh I see. So let\\'s see.\\nUm, so when you\\'re running the EM algorithm,\\nyou never know what are the true values of z, right?\\nYou\\'re- you\\'re given a data set,\\nso you\\'re only told the x\\'s,\\nand as far as we know, uh,\\nthese airplane engines were generated off,\\nyou know, two different Gaussians.\\nMaybe there are two separate assembly processes.\\nYou know, one from the, uh,\\nuh, one from plant number one,\\none from plant number two,\\nand maybe they actually operate a little bit differently,\\nbut by the time they merge onto one, um,\\nuh, you know, by- by the time\\nthe two suppliers of aircraft engines get to you, they\\'ve been mixed together,\\nand so you can\\'t tell anymore which aircraft engine came\\nfrom proce- plant one and which pla- aircraft engine came from plant two.\\nUm, and they you know there are two plants,\\nwhere you just see the stream of aircraft engines,\\nyou\\'re hypothesizing that there are two types.\\nAnd so in every iteration of EM,\\nyou\\'re taking each, uh,\\naircraft engine and guessing, you know, for this one,\\nI think there\\'s 80% chance that it came from process one,\\nand a 20% chance it came from process two,\\nso that\\'s the E-step.\\nAnd then in the M-step,\\nyou look at all the engines that you\\'re kind of guessing were generated by process one,\\nand you update your Gaussian to be a better model for all of the things that\\nwere- that you kind of think were generated by process one.\\nAnd if there\\'s something that you\\'re absolutely sure came from process one,\\nthen it has a weight of one close to one in this.\\nDo you think that was something that, you know,\\nthere\\'s a 10% chance it comes from process one,\\nthen that example is given a lower weight and now you\\nupdate the mean for that Gaussian. That make sense?\\nCool. All right.\\nSo, [NOISE] 33 minutes.\\nYeah.\\nOkay cool. All right.\\nWell I still remember when, um,\\nI was an undergrad doing a summer internship at AT&T Bell Labs.\\nUm, and then someone a few offices down had\\nlearned about EM for the mixture of Gaussians for the first time,\\nand he was running it on his computer,\\nand he\\'s going around to every single office.\\nSaying, \"Oh my God you\\'ve got to check this out,\\nthis is unbelievable look at what this algorithm can do for three mixes of Gaussian. \"\\nSo tha- that shows you,\\nthose are the type of people I hang out with\\n[LAUGHTER].\\nAll right. Um, so in order to derive yo - you know,\\nso -so this is a slightly hand-wavy argument.\\nAs I uh, let\\'s get- let\\'s guess the values of the z\\'s.\\nLet\\'s just have these weights and plug them into maximum likelihood.\\nUm, what I would like to do is give\\na more rigorous de- derivation for why EM Algorithm is a reasonable algorithm,\\nand why it\\'s a maximum likelihood estimation algorithm\\nand why we can expect it to converge.\\nAnd it turns out that rather than just proving,\\nyou know, that this is a sound algorithm,\\nwhat we\\'ll see on Wednesday is that this view of EM, uh,\\nallows us to derive EM in a- in\\na more correct way for other models as well, the mixtures of Gaussian.\\nOn, on Wednesday, we\\'ll talk about,\\nuh, uh a model called factor analysis,\\nit lets you model Gaussians in extremely high dimensional spaces,\\nwhere if you have 1,000 dimensional data,\\nbut only 30 examples,\\nhow do you fit a Gaussian into that?\\nSo we\\'ll talk about that on Wednesday.\\nAnd it turns out this derivation of EM we\\'re\\ngoing to go about- through now is crucial for,\\num, applying EM accurately in- in- in problems like that.\\nOkay, so.\\nUh, in order that live up to that derivation,\\nlet me describe, um, Jensen\\'s inequality.\\nSo let f be a, a convex function.\\nUm, to do EM,\\nwe\\'re actually going to need a concave function,\\nso it\\'ll be all minus of everything,\\nbut we\\'ll get to that in a second.\\nBut so, a convex function means the second derivative is greater than 0,\\nor in other words, it looks like that, right?\\nSo that\\'s a convex function.\\nUh, let x be a random variable.\\nThen f of the expected value of x is less than or equal to the expected value of x.\\nOkay.\\nNow, [NOISE] um, [NOISE]\\nmaybe, um, here\\'s an example. All right.\\nSo here\\'s the, um, let\\'s see,\\nthere\\'s the function f of x,\\nand let\\'s say that these are the values 1, 2, 3, 4, 5.\\nAnd suppose that X is equal to 1 with\\nprobability one-half and is equal to 5 with probability one-half, right?\\nJust for the illustration.\\nThen here is f of 1.\\nHere is f of 5.\\nUm, here is f of 3.\\nAnd f of 3 is f of the expected value of X,\\nright, because so the expected value of X.\\nAnd sometimes I write this without the square brackets, right.\\nIt\\'s the average of X is equal to 3.\\nUm, and so the expected value,\\nexcuse me, f of the expected value of X is equal to this value,\\nwhereas the expected value of f of\\nx is the mean of f of 1 and f of 5.\\nAll right. So the expected value of f of x.\\nF of x is a 50% chance of being f of 1,\\nand a 50% chance of being f of 5.\\nAnd so the expected value of f of x is equal to this value in the middle.\\nIt\\'s really take these two, right.\\nTake this value and this value and take their mean.\\nSo is this value up here, and,\\nand this value is the expected value of f of x.\\nOkay. And so in this example the expected value\\nof f of x is greater than f of the expected value of X,\\nright, as, as predicted by Jensen\\'s inequality.\\nUm, I\\'m gonna just draw one illustration that may or may not help,\\nand some of my friends like it,\\nI sometimes use it but if it\\'s confusing then don\\'t worry about it.\\nBut it turns out that if you draw a line that connects these two,\\nthen the midpoint of this line, um,\\nis the height of f of expected value of x,\\nright, so the height of this.\\nYou know, so, so given these two points,\\nthis point and this point, if you draw this line,\\nit\\'s called a chord, um,\\nthen the height of this point is the expected value of f of x.\\nAnd this point is,\\num, f of the expected value of x.\\nRight. And in any convex function,\\nyou know, really take any convex function.\\nThat\\'s also convex function.\\nIf you draw any chord,\\nthat green point is always higher,\\nright, than that green point which is why- which is\\nanother way of seeing why Jensen\\'s inequality holds true.\\nOkay. If this visualization doesn\\'t help don\\'t worry\\nabout it but it\\'s just a- actually what a lot of\\nmy friends do is we keep on forgetting which direction Jensen\\'s inequality goes.\\n[LAUGHTER] Why are we not using Jensen [LAUGHTER] that\\'s not great.\\nSo a lot of my friends don\\'t remember, we draw this picture and draw that chord,\\nand we quickly figure out which way the inequality goes.\\nUm, all right.\\nSo one addendum further.\\nIf f is strictly greater than 0.\\nAnd so if this is the case,\\nwe say f is strictly convex.\\nThen-\\nOkay.\\nSo, um, let\\'s see, a straight line is also a convex function, right.\\nSo this is a convex function,\\nthis is a convex function and this is a convex function.\\nIt turns out a straight line, that\\'s also a convex function.\\nBut so in this addendum is saying that if f is\\na strictly convex function meaning basically it\\'s now a straight line, right.\\nAnd a bit modern, it\\'s not a straight line.\\nBut if the curvature if it\\'s always bending up, uh,\\nthen the only way for the left and right-hand sides to be equal is if x is a constant,\\nmeaning it\\'s a random variable that always takes on the same value.\\nOkay. So Jensen\\'s inequality says that,\\nyou know, um, left-hand side is going to be the same as right hand side.\\nSorry, I think I reversed the order of these two for that equation that doesn\\'t have it.\\nBut so Jensen equality says\\nleft-hand side is always less than or equal to the right-hand side,\\nand the only way it\\'s equal as if X, you know,\\nis a random variable that always takes on the same value.\\nOkay, yeah.\\nWhat if- What if the value of f of 1 was equal to the value of f of 3. Wouldn\\'t that?\\nYeah. So it turns out what if value f of 1 is equal to the value of f of 3.\\nIt turns out, it does.\\nVary. So let\\'s see.\\nSo one way that [NOISE] could happen would be if the function were like that.\\nAnd then if you take the- draw the chord,\\ntake the mean it\\'s still higher.\\n[inaudible] The point of f of 1. [inaudible]\\nThen it\\'s important. If, if you kind of flat that part here,\\nthen the function is not strictly convex.\\nAnd so it\\'s still less than equal to but it\\'s not,\\nbut they can\\'t be equal to if x is random.\\nOkay. So and we\\'ll use this in a little bit.\\nWe\\'ll actually end up using this.\\nUm, and again for the strict probabilistic, you know,\\nif those of you that, I don\\'t know, take classes in advanced probability,\\nthe technical way of saying x is a constant is x is equal to EX with probability 1.\\nYou know, I, I think that for all practical human purposes\\nyou do not need to worry about this.\\nBut I think if you [LAUGHTER] take a class in measure theory.\\nThe Professor in measure theory will be happy if you say this and you\\nsay x is a constant but maybe, maybe none of you.\\nOkay. Just don\\'t worry about it.\\nUm, oh yes.\\nOkay. Now, um,\\njust one more addendum,\\num, to this is that\\nthe form of Jensen\\'s inequality we are going to use\\nis actually a form for a concave function.\\nSo instead of convex,\\num, I\\'m gonna say concave.\\nAnd so, you know,\\na concave function is just a negative of a convex function, right.\\nIf you take a convex function and take the negative of that, it becomes concave.\\nAnd so the whole thing works with the- with everything flipped around the other way.\\nOkay. And yep, so this is strictly concave.\\nOkay. So the form of Jensen\\'s inequality we are gonna use is actually the, um,\\nconcave form of Jensen\\'s inequality,\\nand we\\'re actually going to apply it to the log function.\\nSo the log function, right.\\nLog x looks like this.\\nAnd so that\\'s a concave function.\\nAnd so the inequality we\\'ll use would be\\nin this direction that I have in orange.\\nAll right.\\nSo here\\'s the density estimation problem.\\nMeaning, density estimation means you want to estimate P of x. All right.\\nSo we have a model\\nfor P of x, z, with parameters theta.\\nAnd so, you know, instead of writing out mu,\\nsigma- mu, sigma, and phi,\\nlike we did for the mixture of Gaussians.\\nI\\'m just gonna capture all the parameters you have.\\nWhatever your parameters are, I\\'m just gonna capture them in one variable theta.\\nAnd you only observe x.\\nSo your training set looks like that.\\nSo the, um, log likelihood of the parameters theta is equal\\nto some of your training examples log P of x_i, parameterized by theta.\\nUm, and this in turn is log of sum over z,\\nP of x_i, z_i parameterized by theta, right.\\nBecause P of x, you know,\\nis just taking the joint distribution and summing out, marginalizing out z_i.\\nOkay. [NOISE] And so what we want is maximum likelihood estimation\\nwhich is define the value of theta that maximizes this log-likelihood.\\nAnd what we would like to do is derive an EM,\\nderive an algorithm which will turn out to be an EM algorithm as\\nan iterative algorithm for finding\\nthe maximum likelihood estimates of the parameters theta.\\n[NOISE]\\nSo, um, let me draw a picture of that,\\nI\\'d like you to keep in mind as we go through the math, which is,\\nyou know, the, the horizontal axis\\nis the space of possible values of the parameters Theta.\\nAnd so there\\'s some function O of Theta that you try to maximize.\\nThis right. And so what EM does is, um,\\nlet\\'s say you initialize Theta as some value, you know,\\nmaybe randomly initialize, um,\\nsim- similar to the k-means cluster centroids.\\nWhere just randomly initialize your mu\\'s with a mixture of Gaussian\\'s.\\nWhat the EM algorithm does is in the E-step,\\nwe\\'re going to construct a lower bound shown in green here for the log-likelihood.\\nAnd this lower bound,\\nthis green curve has two properties.\\nOne is that it is a lower bound.\\nSo everywhere you look, you know,\\nover all values of Theta,\\nthe green curve lies below the blue curve.\\nSo this is a lower bound.\\nAnd the second property that the green curve has is that it is\\nequal to the blue curve at the current value of Theta.\\nOkay. So what the E-step does,\\nuh, which you\\'ll see later on,\\nand just keep this picture in mind as we go through the E-step and the M-step is,\\num, construct the lower bound that looks like this, right.\\nOh, and, and also, uh, to, uh,\\nto foreshadow probably the derivation.\\nRight? There- there was an addendum to Jensen\\'s inequality where we said,\\nwell, under these conditions it holds with equality.\\nRight. E of f of x equals f of e of x.\\nWe said, \"Well, the two things are equal with under certain conditions.\"\\nUm, we want things to be equal.\\nWe want the green curve to be equal to the blue curve at the old value of Theta.\\nSo we- we\\'ll use that addendum to Jensen\\'s inequality when we drive that.\\nUm, so this E-step is draw the green curve.\\nAnd then what the M-step does is it takes a green curve,\\nand then it finds the maximum.\\nActually, certainly stroke [inaudible] so I\\'ll draw in green.\\nWhat the M-step does is it takes the green curve,\\nand it finds the maximum.\\nAnd one step of EM will then move Theta from this green value to this red value.\\nOkay. So the E-step constructs the green curve,\\nand the M-step, uh,\\nfinds the maximum of the green curve.\\nAnd this is one iteration of EM.\\nThe second iteration of EM,\\nnow that you\\'re at this red thing is will construct a new lower bound,\\nand then again, you use a different lower bound.\\nEverywhere the red curve is below the blue curve,\\nand the values are equal at this new value.\\nThat\\'s the E-step, and then M-step will maximize this red curve,\\num, and so on. Now you\\'re here.\\nConstruct another thing, do that.\\nRight. And you can kinda tell that as you keep running EM,\\nthis is constantly trying to increase L of Theta.\\nTrying to increase the log-likelihood,\\nuntil it converges to a local optimum.\\nOkay. Um, the EM algorithm does converge only to local optimum.\\nSo if, you know, there was another even bigger thing there that it may never\\nfind its way over to that other- that, uh, better optimum.\\nBut the EM algorithm by repeatedly doing this,\\nwill hopefully converge to a pretty good local optimum.\\nOkay. All right.\\nSo let\\'s write on how we do that.\\nUm, let me think.\\nActually, let me use the other board.\\nNo, I think this is okay. All right.\\nSo I\\'ve already said that our goal is to find the parameters theta that maximize this.\\n[NOISE] All right.\\nUh, and so that equation we said are just now is sum over i log,\\nsum over zi, p of\\nxi comma zi given Theta.\\nOkay. So this is just what we had written down,\\nI guess, uh, on the left.\\nWhat I\\'m going to do next is,\\num, divide by- [NOISE]\\nmultiply and divide by this.\\nOkay. Um, where Qi of zi is a probability distribution,\\ni.e., the sum over zi,\\nQi of zi equals 1.\\nOkay. So I\\'m going to multiply and divide by some probability distribution,\\nand we\\'ll, we\\'ll decide later\\nhow to come up with this probability distribution Qi, right.\\nBut, you know, I\\'m allowed to construct\\na probability distribution and multiply and divide by the same thing.\\nRight. Now, if you look at this,\\nall right, let\\'s put square brackets here.\\nIf this Qi, that is the probability distribution meaning that sum over zi Qi,\\nzi sums over- sums to 1.\\nThen this thing inside is, um,\\nequal to sum over i log of an expected value of zi\\ndrawn from the Qi distribution of [NOISE] right, actually, if I,\\nlet me use colors to make this clearer.\\nRight. So the way you compute the expected value of z-, you know,\\nsome function of zi is you sum over all the possible values of\\nzi of the probability of zi times whatever that function is.\\nSo this equation is just the expected value with respect to zi\\ndrawn from that Qi distribution of that thing in the square brackets,\\nin the purple square brackets.\\nNow, using the, um,\\nconcave form of Jensen\\'s inequality,\\nwe have that this is greater than\\nor equal to [NOISE].\\nSo this is a form of Jensen\\'s inequality where,\\num, f of E, x is greater than or equal to E of f of x,\\nwhere here, um, this is the logarithmic function.\\nRight. So the log function is a concave function. It looks like that.\\nAnd so, um, using the,\\nI guess here using,\\nusing the form Jensen\\'s inequality with the signs reversed, um.\\nRight, f of Ex is greater than equals E of fx.\\nSo you get log of expectation is greater than equal to expectation of the log, all right.\\nAnd then finally, let me just take this expectation and unpack it one more time.\\nSo this is now sum over i, sum over zi.\\n[NOISE].\\nOkay. So I just took this expected value and\\nturned it back into the sum of the random variable probability, times that thing.\\nOkay. So, um, if you remember this picture from the middle,\\nwhat we wanted to do was to construct a function,\\nconstruct this green curve.\\nThere\\'s a lower bound for the blue curve.\\nAnd if you view this formula here as a function of Theta right,\\nso your x, um, x is just your data,\\nand z is a variable you sum over.\\nSo this whole thing is the function of Theta, right?\\nBecause x\\'s are fixed,\\nz is just something you f- sum over.\\nSo this whole formula here,\\nthis is a function of the parameters Theta.\\nAnd what we\\'ve shown is that this thing, you know,\\nthis formula here, this is a lower bound for the log-likelihood,\\nuh, for- for, for, for this thing.\\nI guess this is L of Theta.\\nSo- go ahead.\\n[inaudible].\\nOh, how I got to this equation?\\nUh, sure. Um, let me think.\\nSo let\\'s see. What\\'s a good way to do this?\\nUm, uh, yeah.\\nLet\\'s say that z takes on values from 1 through 5, right.\\nLet\\'s say z takes on values from 1 through 10.\\nSo you roll a 10 sided dice.\\nAnd I want to compute, um, you know,\\nthe expected value of, uh,\\nsome function of, of some function g, g of z.\\nRight. Then the expected value of g of z is sum of\\nall the possible values of z of the probability that you get that z,\\ntimes g of z.\\nRight. So that\\'s, that\\'s what\\'s the expected value is of a function of a random variable.\\nAnd, and this is- and the expected value of z is sum over z,\\nP of z times z.\\nThat\\'s the average of random variable.\\nAnd so, um, in the notation that we have,\\nthe probability of z taking on different values is denoted by Qi of z,\\nwhich is why we wind up with that formula.\\nDoes that makes sense? Does it?\\nOkay. Is that okay? Does that make sense? Yeah. All right.\\nIf, if one of these steps doesn\\'t make sense, let me know.\\nTh- other questions?\\nOkay. All right.\\nHope that makes sense. [NOISE]. Um. [NOISE]\\nNow, one of the things we want when constructing\\nthis green lower bound is we want that green lower\\nbound to be equal to the blue function at this point, right?\\nAnd this is actually how you guarantee that when you optimize the green function.\\nBy improving on the green function,\\nyou\\'re improving on the blue function.\\nSo we want this lower bound to be tight.\\nRight, the, the two functions be equal, tangent to each other.\\nSo in other words we want this inequality to hold with equality.\\nSo we want, um, yeah,\\nso we want the left hand side and the right hand side to be equal\\nfor the current value of Theta, right?\\n[NOISE]\\nSo on a given iteration of EM where\\nthe current parameters are equal to Theta, we want,\\nwe want- I know this was a lot of math but, you know,\\nwe want the left and right hand sides to be equal to each other.\\nRight. Because that\\'s what it means for,\\nuh, for the lower bound to be tight,\\nfor the green color to be exactly touching\\nthe blue curve as we construct that lower bound.\\nAnd so for this to be true,\\nwe need the random variable inside to be a constant.\\nSo we need P of x_i, z_i,\\ndivided by Qi of z_i to be equal to const- to, to a constant.\\nMeaning that no matter what value of z_i you plug in,\\nthis should evaluate to the same value.\\nIn other words, the ratio between the numerator and denominator must be the same.\\nUm, unfortunately so far,\\nwe have not yet specified,\\nhow we choose this distribution for z_i, right.\\nSo, so far the only constraint we have is that\\nQi has to be a probability density- has to be a probability distribution over z_i,\\nbut you could choose one of the distributions you want for z_i.\\nAnd it turns out that, um, uh,\\nwe can set Qi of z_i to be proportional to p of x_i,\\nz_i parameterized by Theta.\\nAnd this means that for any value of z,\\nyou know, so z_indicates as it could from Gaussian one and Gaussian two.\\nRight. So this means that the chance of Gaussian one is\\nproportional to the chance of Gaussian one versus Gaussian two.\\nWhether z_i takes on one or two is proportional to this.\\nAnd I don\\'t want to prove it but one way to ensure this,\\nand this is proven in the lecture notes.\\nBut it turns out that one way to ensure.\\nUm, well so the Qis need to sum to 1.\\nSo one way to ensure that this is proportional to\\nthe right-hand side is to just take the right-hand side.\\nSorry. Let me move here.\\nSo one- so let\\'s see.\\nRight. So the Qis have to sum to 1.\\nAnd so one way to ensure the proportionality is to just take the right-hand side,\\nand normalize it to sum to 1.\\nUm, and after, after a couple of\\nsteps that are in the lecture notes but I don\\'t want to do here,\\nyou can show that this results in sending Qi of z_i to be equal to that,\\nthat posterior probability, okay?\\nAnd so, um, sorry I skipped a couple steps here.\\nYou can get from the lecture notes,\\nbut it turns out that if you want this to be\\na constant meaning whether you plugged in z_i equals 1 or z_i equals 2 or whatever,\\nthese evaluate to the same constant.\\nThe only way to do that is make sure\\nthe numerator and denominator are proportional to each other.\\nAnd because Qi of z_i is a density that must sum to 1.\\nOne way to make sure they\\'re proportional is to just\\nset this to be with the right-hand side but normalize the sum to 1.\\nOkay. And we derived this a little bit more carefully in the lecture notes.\\nSo just to summarize,\\nthis gives us the EM algorithm.\\nLet\\'s take all of this- everything we just did and wrap in the EM algorithm.\\nIn the E-step, we\\'re going to set Qi of\\nz_i equal to that.\\nAnd previously this was the w_i_js.\\nRight. So instead of- so previously,\\nwe\\'re restoring these probabilities in the variables you call w_i_js.\\nAnd then in the M-step,\\nwe\\'re going to take that lower bound that we constructed,\\nwhich is this function,\\nand maximize it with respect to Theta.\\nOkay. Um, and so remember in the M-step we\\nconstructed this thing on the right-hand side as a lower bound for the log-likelihood.\\nAnd so for the fixed value of Q,\\nyou can maximize this with respect to Theta and that updates the Theta,\\nyou know, maximizing the green lower boundary,\\nthat\\'s what the M-step does.\\nAnd if you iterate these two steps,\\nthen you find that this should converge to a local optima.\\nOkay. Oh and just maybe that\\'s the obvious question.\\nUm, why don\\'t we try to maximize right Theta,\\nuh, why are we trying to maximize the log-likelihood directly?\\nIt turns out that if you take the mixture of Gaussians model,\\ntry to take derivatives of this and set derivatives equal to 0,\\nthere\\'s no known way to solve for the value of Theta that maximizes the log-likelihood.\\nBut you find that for the mixture of Gaussians model and for\\nmany models including factor analysis that we talked about on Wednesday,\\nif you actually plug in the Gaussian density- uh,\\nif you actually plug in that mixture of Gaussians model for P,\\num, and take, you know,\\ntake, take derivatives, set derivatives equal to 0 and solve,\\nyou will be able to find an analytic solution to maximize this M step,\\nand that\\'ll be exactly what we had worked out in the early derivation of the EM algorithm.\\nOkay. But so this derivation shows that,\\nuh, the EM algorithm, you know,\\nis a maximum likelihood estimation algorithm with\\noptimization solved by constructing lower bounds and optimizing lower bounds, okay?\\nAll right. Um, that\\'s it for today,\\nand only it\\'s stuff up to here,\\nright, and so this stuff will be up\\nto the midterm but we\\'ll talk about factor analysis\\na lot on Wednesday, but it will not be on the midterm.\\nOkay. So let\\'s break for today, and I\\'ll see you guys on Wednesday.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b912296d",
   "metadata": {
    "papermill": {
     "duration": 0.003297,
     "end_time": "2026-01-01T15:47:44.628437",
     "exception": false,
     "start_time": "2026-01-01T15:47:44.625140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# load summrizing pipeline\n",
    "* the used model [facebook/bart-large-cnn] limit is *1024 tokens*.\n",
    "* so we will be using *chunking*\n",
    "* By spliting the long lecture/video into small pieces\n",
    "* summarizes each piece, and gives you a full summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c17f1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:47:44.636336Z",
     "iopub.status.busy": "2026-01-01T15:47:44.635719Z",
     "iopub.status.idle": "2026-01-01T15:47:57.237321Z",
     "shell.execute_reply": "2026-01-01T15:47:57.236434Z"
    },
    "papermill": {
     "duration": 12.607426,
     "end_time": "2026-01-01T15:47:57.239149",
     "exception": false,
     "start_time": "2026-01-01T15:47:44.631723",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.38.0)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\r\n",
      "Collecting accelerate\r\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\r\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\r\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\r\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.15.2\r\n",
      "    Uninstalling tokenizers-0.15.2:\r\n",
      "      Successfully uninstalled tokenizers-0.15.2\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.38.0\r\n",
      "    Uninstalling transformers-4.38.0:\r\n",
      "      Successfully uninstalled transformers-4.38.0\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 1.11.0\r\n",
      "    Uninstalling accelerate-1.11.0:\r\n",
      "      Successfully uninstalled accelerate-1.11.0\r\n",
      "Successfully installed accelerate-1.12.0 tokenizers-0.22.1 transformers-4.57.3\r\n"
     ]
    }
   ],
   "source": [
    "# Run this cell FIRST every time you start a new session!\n",
    "!pip install -U transformers accelerate\n",
    "\n",
    "# Only uncomment the line below if you are starting a fresh session\n",
    "# import os\n",
    "# os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7079cfe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T15:47:57.250049Z",
     "iopub.status.busy": "2026-01-01T15:47:57.249372Z",
     "iopub.status.idle": "2026-01-01T15:48:51.489231Z",
     "shell.execute_reply": "2026-01-01T15:48:51.488277Z"
    },
    "papermill": {
     "duration": 54.2469,
     "end_time": "2026-01-01T15:48:51.490792",
     "exception": false,
     "start_time": "2026-01-01T15:47:57.243892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 15:48:08.703134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767282488.906305      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767282488.961165      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767282489.441083      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767282489.441137      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767282489.441140      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767282489.441142      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4525f5459b0546e58465f1df9f3d545f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef42b91596b4b42854c35688a485668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9d3f9512f54cdfacb8b00500f8129b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7c86c78c7f48faa9a8cd1a8c0b11e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88116310c904541b2a42c50e232af1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497c003d7df54fb3956cadcb6405d608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing video...\n",
      "Processing chunk 1/19...\n",
      "Processing chunk 2/19...\n",
      "Processing chunk 3/19...\n",
      "Processing chunk 4/19...\n",
      "Processing chunk 5/19...\n",
      "Processing chunk 6/19...\n",
      "Processing chunk 7/19...\n",
      "Processing chunk 8/19...\n",
      "Processing chunk 9/19...\n",
      "Processing chunk 10/19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 11/19...\n",
      "Processing chunk 12/19...\n",
      "Processing chunk 13/19...\n",
      "Processing chunk 14/19...\n",
      "Processing chunk 15/19...\n",
      "Processing chunk 16/19...\n",
      "Processing chunk 17/19...\n",
      "Processing chunk 18/19...\n",
      "Processing chunk 19/19...\n",
      "\n",
      "--- FINAL VIDEO SUMMARY ---\n",
      "\n",
      "The class midterm is this Wednesday and it's 48-hour take-home midterm. The first unsupervised learning algorithm we'll talk about is clustering. The most common uses of clustering is, uh, market segmentation. A clustering algorithm can be used to find clusters of dots near each other. The color of the dots depends on which cluster centroid is closer. The algorithm converges even if you keep running the algorithm. The algorithm is the same either way. It turns out that the algorithm can be proven to converge. The algorithm is written out in the lecture notes, but it turns out if you write it out as a function, it will cost less. The most frequently asked question I get for k-means is how do you choose k? It turns out that in unsupervised learning, sometimes it's just ambiguous, right? K-means gets stuck on sort of local minima sometimes. If you're worried about localMinima, you can do, uh, 10 times, or 100 times or 1000 times from different random initializations of the cluster centroids. Anomaly detection is used for inspecting, inspecting and inspecting data. It is also used for computer security. An algorithm is developed to model the mixture of Gaussians model. The EM algorithm or the expectation-maximization algorithm will allow us to, uh,fit a model despite not knowing which Gaussian each example that come from. The model is very similar to the model you saw in Gaussian discriminant analysis. The EM algorithm is based on the Gaussian discriminant analysis. It uses a hidden random variable z_i that you don't get to see in the training set. If we knew the value of the z's, we could use maximum likelihood estimation. The EM algorithm has two steps. The E-step is set to w i j. The expectation step is the probability that z_i is equal to j. And so to compute this, you use a similar Bayes' rule type of calculation. The EM algorithm is a mixture of two Gaussians. It's a little bit like k-means but with soft assignment. In the first step, we use the formulas we have for maximum likelihood estimation. And in the second, we update the means accordingly. The algorithm is based on a mixture of two Gaussians, one thin narrow Gaussian here and one much wider fatter Gaussian. This will allow you to fit a probability density function that puts a lot of probability models on. The EM algorithm is based on the idea that aircraft engines are generated off of two different Gaussians. By the time the two suppliers of aircraft engines get to you, they've been mixed together, so you can't tell anymore which aircraft engine came from which plant. On Wednesday, we'll talk about a model called factor analysis. It lets you model Gaussians in extremely high dimensional spaces. The derivation of EM we're going to go through now is crucial for applying EM accurately. Jensen's inequality says that left-hand side is going to be the same as right hand side. The only way for the left and right-hand sides to be equal is if x is a constant, meaning it's a random variable that always takes on the same value. The EM algorithm is an iterative algorithm for finding the maximum likelihood estimates of the parameters theta. It is similar to the k-means cluster centroids. The algorithm is based on Jensen's inequality. The E-step constructs the green curve, and the M-step, uh, finds the maximum. The second iteration of EM will construct a new lower bound, and then again, you use a different lower bound. As you keep running EM, this is constantly trying to increase L of Theta. The expected value of z is sum over z, P of z times g of z. The log function is a concave function. The expected value is a lower bound for the log-likelihood of a function. In EM, we want the left and right hand sides to be equal to each other. We want the lower bound to be tight, for the green color to be exactly touching the blue curve. We need the random variable inside to be a constant. In the E-step, we're going to set Qi of z_i equal to that. The M-step is about maximizing the lower bound for the log-likelihood. The EM algorithm is a maximum likelihood estimation algorithm.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import math\n",
    "\n",
    "# Load the model on GPU\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "\n",
    "#  function that split text into chunks\n",
    "def chunk_text(text, max_chunk_size=3000):\n",
    "    \n",
    "    # 3000 characters is roughly 700-800 tokens, which is safe for BART (limit 1024)\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), max_chunk_size):\n",
    "        chunks.append(text[i:i + max_chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# 3. Process the long video transcript\n",
    "print(\"Summarizing video...\")\n",
    "chunks = chunk_text(text)\n",
    "full_summary = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Skip very short chunks (like the very end)\n",
    "    if len(chunk) < 100:\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "    \n",
    "    # Summarize this specific chunk\n",
    "    # We use truncation=True just in case, but our manual splitting prevents the crash\n",
    "    summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False, truncation=True)\n",
    "    full_summary.append(summary[0]['summary_text'])\n",
    "\n",
    "# 4. Combine and print the final result\n",
    "print(\"\\n--- FINAL VIDEO SUMMARY ---\\n\")\n",
    "final_text = \" \".join(full_summary)\n",
    "print(final_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 90.097945,
   "end_time": "2026-01-01T15:48:54.331766",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-01T15:47:24.233821",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0013afcf03224f41ab3e6598dd588f42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0020bc2845ba4db3acec6a9627a29ad9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "02c78f7d71c0492bb4d5e13bf12612c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3aaf950e5eb647e682c4ccc508c13386",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_3d4b63cc4279431f899d4818d99ab9a0",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:‚Äá"
      }
     },
     "0726be0204a24d1c970a28f6b077d693": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "09696acd8fe147fa97e83c19d6aff970": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bacc52333b1b466886c6a810601aa5f2",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f502cb0a94154410b5ff9856a272fe0a",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.63G/1.63G‚Äá[00:04&lt;00:00,‚Äá894MB/s]"
      }
     },
     "0aef8246e59342dbac66a6436d3453d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58fc0263aa6943b0aeb8f69c9f110528",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7057c065a9ae44b2bc78d73c561523bc",
       "tabbable": null,
       "tooltip": null,
       "value": "generation_config.json:‚Äá100%"
      }
     },
     "11eda0f4e2954087a6eeff24d9894150": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_22f2db5c55b5461ba4c587807172ff1d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_2e0afd9a21d64f7983536cf61a9f818e",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:‚Äá"
      }
     },
     "12b43a1631bb4c3f8e8317871924ad65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80cb855f0099466cb13de95bafec2fe8",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_a28b49d5d11c4937bcb393571cc4562f",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá899k/?‚Äá[00:00&lt;00:00,‚Äá21.9MB/s]"
      }
     },
     "12cd6aff677f4b9ca553f6dd66d61ff4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17fbcbe11e6d4016bf699696831fcf3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22f2db5c55b5461ba4c587807172ff1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c2822e1c5284d36af54e6a023c6ef8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_17fbcbe11e6d4016bf699696831fcf3c",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_80b32272c4cb4835886d627b6177d9b3",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:‚Äá"
      }
     },
     "2e0afd9a21d64f7983536cf61a9f818e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3547a2d2070345d0816602da07a6b417": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "365ae05a04ea40f3b25c553118da2a80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac91369eb6c74cc09c7d55ef2b6931c9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c562914713374d92908572ac3ffcb510",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "3aaf950e5eb647e682c4ccc508c13386": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b78306b8b7e4cefaca0625dd87c1037": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d4b63cc4279431f899d4818d99ab9a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42c9b525640f434f845862307c5f014b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6bedf05cbb8c41e98cae2896cf587eef",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3547a2d2070345d0816602da07a6b417",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "43fe77866ada4443ba8964a6f59878b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4525f5459b0546e58465f1df9f3d545f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c2822e1c5284d36af54e6a023c6ef8c",
        "IPY_MODEL_365ae05a04ea40f3b25c553118da2a80",
        "IPY_MODEL_f844d4ddd2f946c0b467bc944ad8589c"
       ],
       "layout": "IPY_MODEL_ca17a4b2574a4a21b977bff7c5b6654f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "497c003d7df54fb3956cadcb6405d608": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11eda0f4e2954087a6eeff24d9894150",
        "IPY_MODEL_7c9b3cc1eafa4a6c95937696bd2452ce",
        "IPY_MODEL_4c399efeffdd45e593cf514e89ba3802"
       ],
       "layout": "IPY_MODEL_8476ce38ce5e458b8ae1b9ed4b6193c1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4c399efeffdd45e593cf514e89ba3802": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_af53c757c3b9431aacd2409a73fe3325",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_4f38dbf1a62e41a29a7bbd51a137efee",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.36M/?‚Äá[00:00&lt;00:00,‚Äá73.1MB/s]"
      }
     },
     "4f38dbf1a62e41a29a7bbd51a137efee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "58fc0263aa6943b0aeb8f69c9f110528": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d639f3f13494361993427ef170b1979": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6346c3fa43f64117aaec2cb0bb2ec093",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_0013afcf03224f41ab3e6598dd588f42",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:‚Äá"
      }
     },
     "6346c3fa43f64117aaec2cb0bb2ec093": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6603d4dcb1ab40dc8f030003b152e4eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67131e7aea50459987798f4d58d58b23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d32bb4b2f83c456c81fc8b40da849516",
       "max": 363.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a5831e97c9d74fa692f60104c52775a5",
       "tabbable": null,
       "tooltip": null,
       "value": 363.0
      }
     },
     "671cb8bf8ce64c02bb15eb28523a6380": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "6bedf05cbb8c41e98cae2896cf587eef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "6e38bf8758844c989d691f06d5996fbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6e9d3f9512f54cdfacb8b00500f8129b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0aef8246e59342dbac66a6436d3453d5",
        "IPY_MODEL_67131e7aea50459987798f4d58d58b23",
        "IPY_MODEL_d6b528140ccc42eca2d602a325f8664e"
       ],
       "layout": "IPY_MODEL_b3b8fcf237ca49a393fdec27920b394d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7057c065a9ae44b2bc78d73c561523bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "70ba0621c7d0428f983d1e085f6582cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_97b4503ec39c4d289f9980be6319e24a",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7104c2cfda2a48dc9ac5dea750929b08",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:‚Äá100%"
      }
     },
     "7104c2cfda2a48dc9ac5dea750929b08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7146f6c8f20749c2a039f5b8d67533f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c12c543ad76646d795d47270272c3ac2",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6e38bf8758844c989d691f06d5996fbd",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "7c9b3cc1eafa4a6c95937696bd2452ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_671cb8bf8ce64c02bb15eb28523a6380",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a037974350c14383ac94a94b9558fb7e",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "80b32272c4cb4835886d627b6177d9b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "80cb855f0099466cb13de95bafec2fe8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8476ce38ce5e458b8ae1b9ed4b6193c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "858c66cdf39c4c08899171cc4f4592fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ef42b91596b4b42854c35688a485668": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_70ba0621c7d0428f983d1e085f6582cc",
        "IPY_MODEL_e2f1df931dd34bff9f7b07301d0ad453",
        "IPY_MODEL_09696acd8fe147fa97e83c19d6aff970"
       ],
       "layout": "IPY_MODEL_9cf03dbe03624dde929c58e5d5e375ca",
       "tabbable": null,
       "tooltip": null
      }
     },
     "97b4503ec39c4d289f9980be6319e24a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cf03dbe03624dde929c58e5d5e375ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a037974350c14383ac94a94b9558fb7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a28b49d5d11c4937bcb393571cc4562f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a5831e97c9d74fa692f60104c52775a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ac91369eb6c74cc09c7d55ef2b6931c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "af53c757c3b9431aacd2409a73fe3325": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af7c86c78c7f48faa9a8cd1a8c0b11e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_02c78f7d71c0492bb4d5e13bf12612c4",
        "IPY_MODEL_42c9b525640f434f845862307c5f014b",
        "IPY_MODEL_12b43a1631bb4c3f8e8317871924ad65"
       ],
       "layout": "IPY_MODEL_c522b25fc9eb4155a07a9af714c91ec7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b3b8fcf237ca49a393fdec27920b394d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bacc52333b1b466886c6a810601aa5f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c12c543ad76646d795d47270272c3ac2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "c522b25fc9eb4155a07a9af714c91ec7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c562914713374d92908572ac3ffcb510": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca17a4b2574a4a21b977bff7c5b6654f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d32bb4b2f83c456c81fc8b40da849516": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3f0dcbc9aa642099b609aaab42781f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f61227d4c4e547c59d6e4821fc7e573c",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_12cd6aff677f4b9ca553f6dd66d61ff4",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá456k/?‚Äá[00:00&lt;00:00,‚Äá35.8MB/s]"
      }
     },
     "d6b528140ccc42eca2d602a325f8664e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_858c66cdf39c4c08899171cc4f4592fb",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_43fe77866ada4443ba8964a6f59878b1",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá363/363‚Äá[00:00&lt;00:00,‚Äá30.9kB/s]"
      }
     },
     "d8c5ea5b4cb44a13b8a1fe47a526a44d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2f1df931dd34bff9f7b07301d0ad453": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6603d4dcb1ab40dc8f030003b152e4eb",
       "max": 1625222120.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0726be0204a24d1c970a28f6b077d693",
       "tabbable": null,
       "tooltip": null,
       "value": 1625222120.0
      }
     },
     "e88116310c904541b2a42c50e232af1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5d639f3f13494361993427ef170b1979",
        "IPY_MODEL_7146f6c8f20749c2a039f5b8d67533f9",
        "IPY_MODEL_d3f0dcbc9aa642099b609aaab42781f8"
       ],
       "layout": "IPY_MODEL_d8c5ea5b4cb44a13b8a1fe47a526a44d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f502cb0a94154410b5ff9856a272fe0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f61227d4c4e547c59d6e4821fc7e573c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f844d4ddd2f946c0b467bc944ad8589c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3b78306b8b7e4cefaca0625dd87c1037",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_0020bc2845ba4db3acec6a9627a29ad9",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.58k/?‚Äá[00:00&lt;00:00,‚Äá149kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
